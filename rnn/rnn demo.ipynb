{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "num_steps = 10 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(size=10000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "RNN Inputs\n",
    "\"\"\"\n",
    "\n",
    "# Turn our x placeholder into a list of one-hot tensors:\n",
    "# rnn_inputs is a list of num_steps tensors with shape [batch_size, num_classes]\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack:0' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:1' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:2' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:3' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:4' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:5' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:6' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:7' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:8' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:9' shape=(200, 2) dtype=float32>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot:0' shape=(200, 10, 2) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def rnn_cell(rnn_input, state):\n",
    "     return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = init_state\n",
    "rnn_outputs = []\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "#losses and train_step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \\\n",
    "          logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nEPOCH', 0)\n",
      "('Average loss at step', 100, 'for last 250 steps:', 0.6345799714326859)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.6181924998760223)\n",
      "('Average loss at step', 300, 'for last 250 steps:', 0.578036373257637)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.56263367831707)\n",
      "('Average loss at step', 500, 'for last 250 steps:', 0.5585931295156479)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.5552406972646713)\n",
      "('Average loss at step', 700, 'for last 250 steps:', 0.5318690532445908)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.5197407624125481)\n",
      "('Average loss at step', 900, 'for last 250 steps:', 0.5201387602090836)\n",
      "('Average loss at step', 1000, 'for last 250 steps:', 0.5195682537555695)\n",
      "('Average loss at step', 1100, 'for last 250 steps:', 0.5171463513374328)\n",
      "('Average loss at step', 1200, 'for last 250 steps:', 0.518247380554676)\n",
      "('Average loss at step', 1300, 'for last 250 steps:', 0.5141864150762558)\n",
      "('Average loss at step', 1400, 'for last 250 steps:', 0.5134176737070084)\n",
      "('Average loss at step', 1500, 'for last 250 steps:', 0.5137457007169723)\n",
      "('Average loss at step', 1600, 'for last 250 steps:', 0.5134075996279717)\n",
      "('Average loss at step', 1700, 'for last 250 steps:', 0.5132906135916709)\n",
      "('Average loss at step', 1800, 'for last 250 steps:', 0.5124973633885384)\n",
      "('Average loss at step', 1900, 'for last 250 steps:', 0.5120569530129433)\n",
      "('Average loss at step', 2000, 'for last 250 steps:', 0.5102386921644211)\n",
      "('Average loss at step', 2100, 'for last 250 steps:', 0.5122968336939812)\n",
      "('Average loss at step', 2200, 'for last 250 steps:', 0.5133229169249535)\n",
      "('Average loss at step', 2300, 'for last 250 steps:', 0.5126294973492622)\n",
      "('Average loss at step', 2400, 'for last 250 steps:', 0.511219200193882)\n",
      "('Average loss at step', 2500, 'for last 250 steps:', 0.5128359791636466)\n",
      "('Average loss at step', 2600, 'for last 250 steps:', 0.5118915694952011)\n",
      "('Average loss at step', 2700, 'for last 250 steps:', 0.5124779975414276)\n",
      "('Average loss at step', 2800, 'for last 250 steps:', 0.5121248707175254)\n",
      "('Average loss at step', 2900, 'for last 250 steps:', 0.5119733837246895)\n",
      "('Average loss at step', 3000, 'for last 250 steps:', 0.5108011129498482)\n",
      "('Average loss at step', 3100, 'for last 250 steps:', 0.5114825141429901)\n",
      "('Average loss at step', 3200, 'for last 250 steps:', 0.5100993323326111)\n",
      "('Average loss at step', 3300, 'for last 250 steps:', 0.5111513036489487)\n",
      "('Average loss at step', 3400, 'for last 250 steps:', 0.5120068389177322)\n",
      "('Average loss at step', 3500, 'for last 250 steps:', 0.5108745980262757)\n",
      "('Average loss at step', 3600, 'for last 250 steps:', 0.5114901560544968)\n",
      "('Average loss at step', 3700, 'for last 250 steps:', 0.5103642612695694)\n",
      "('Average loss at step', 3800, 'for last 250 steps:', 0.5105317994952202)\n",
      "('Average loss at step', 3900, 'for last 250 steps:', 0.5105709627270698)\n",
      "('Average loss at step', 4000, 'for last 250 steps:', 0.511049981713295)\n",
      "('Average loss at step', 4100, 'for last 250 steps:', 0.5108516836166381)\n",
      "('Average loss at step', 4200, 'for last 250 steps:', 0.5126524156332016)\n",
      "('Average loss at step', 4300, 'for last 250 steps:', 0.5109646618366241)\n",
      "('Average loss at step', 4400, 'for last 250 steps:', 0.5107187461853028)\n",
      "('Average loss at step', 4500, 'for last 250 steps:', 0.511099896132946)\n",
      "('Average loss at step', 4600, 'for last 250 steps:', 0.5108020347356796)\n",
      "('Average loss at step', 4700, 'for last 250 steps:', 0.5094276776909828)\n",
      "('Average loss at step', 4800, 'for last 250 steps:', 0.509258853495121)\n",
      "('Average loss at step', 4900, 'for last 250 steps:', 0.5129020881652832)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x104079990>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(1,num_steps)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
