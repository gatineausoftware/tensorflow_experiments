{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a encoder-decoder model order input from least to greastest.  first step just return the indices of fixed lenght input, second step variable lenght input, embedding layer and pointer network. \n",
    "\n",
    "Note that sequences are of fixed lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Global config variables\n",
    "num_steps = 4 \n",
    "batch_size = 16\n",
    "state_size = 12\n",
    "learning_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_data(time_steps=4, batch_size=16, num_batches=4000):\n",
    "    X = np.random.rand(num_batches * batch_size, time_steps)\n",
    "    Y = np.asarray([np.argsort(e) for e in X])\n",
    "    for i in range(num_batches):\n",
    "        _x = X[i * batch_size:(i + 1) * batch_size]\n",
    "        _y = Y[i * batch_size:(i + 1) * batch_size]\n",
    "        yield _x, _y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.float32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "RNN Inputs\n",
    "\"\"\"\n",
    "\n",
    "# Turn our x placeholder into a list of one-hot tensors:\n",
    "# rnn_inputs is a list of num_steps tensors with shape [batch_size, num_classes]\n",
    "rnn_inputs = tf.expand_dims(x, 2)\n",
    "rnn_inputs = tf.unstack(rnn_inputs, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [1 + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def rnn_cell(rnn_input, state):\n",
    "     print rnn_input\n",
    "     print state\n",
    "     return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"unstack:0\", shape=(16, 1), dtype=float32)\n",
      "Tensor(\"zeros:0\", shape=(16, 12), dtype=float32)\n",
      "Tensor(\"unstack:1\", shape=(16, 1), dtype=float32)\n",
      "Tensor(\"Tanh:0\", shape=(16, 12), dtype=float32)\n",
      "Tensor(\"unstack:2\", shape=(16, 1), dtype=float32)\n",
      "Tensor(\"Tanh_1:0\", shape=(16, 12), dtype=float32)\n",
      "Tensor(\"unstack:3\", shape=(16, 1), dtype=float32)\n",
      "Tensor(\"Tanh_2:0\", shape=(16, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "state = init_state\n",
    "rnn_outputs = []\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'mul:0' shape=(16, 1) dtype=float32>,\n",
       " <tf.Tensor 'unstack_1:0' shape=(16, 1) dtype=int32>,\n",
       " <tf.Tensor 'unstack_1:1' shape=(16, 1) dtype=int32>,\n",
       " <tf.Tensor 'unstack_1:2' shape=(16, 1) dtype=int32>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoder inputs\n",
    "\n",
    "# rnn_inputs is a list of num_steps tensors with shape [batch_size, num_classes]\n",
    "decoder_inputs = tf.expand_dims(y, 2)\n",
    "decoder_inputs = tf.unstack(decoder_inputs, axis=1)\n",
    "\n",
    "#we want to insert starter symbols at beginning of list and drop last element of list\n",
    "start = tf.ones([batch_size, 1])\n",
    "start = tf.scalar_mul(-1, start)\n",
    "decoder_inputs.insert(0, start)\n",
    "del decoder_inputs[-1]\n",
    "decoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder cell\n",
    "with tf.variable_scope('decoder_cell'):\n",
    "    Wd = tf.get_variable('W', [1 + state_size, state_size])\n",
    "    bd = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_cell_d(decoder_input, state):\n",
    "     return tf.tanh(tf.matmul(tf.concat([decoder_input, state], 1), Wd) + bd)\n",
    "    \n",
    "state = final_state\n",
    "decoder_outputs = []\n",
    "for decoder_input in decoder_inputs:\n",
    "    state = rnn_cell_d(rnn_input, state)\n",
    "    decoder_outputs.append(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = num_steps\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = [tf.matmul(decoder_output, W) + b for decoder_output in decoder_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "#losses and train_step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \\\n",
    "          logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_network(num_epochs, num_steps, state_size, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for i in range(num_epochs):\n",
    "            training_loss = 0\n",
    "\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", i)\n",
    "            d = gen_data(time_steps=4, batch_size=16, num_batches=4000)\n",
    "            for j in range(4000):\n",
    "                X,Y = d.next()\n",
    "                training_state = np.zeros((batch_size, state_size))\n",
    "                tr_losses, training_loss_, training_state, _, preds_ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step,\n",
    "                              predictions],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "\n",
    "                if j % 40 == 0 and j > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", j,\n",
    "                              \"for last 250 steps:\", training_loss / 100)\n",
    "                    training_losses.append(training_loss / 100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nEPOCH', 0)\n",
      "('Average loss at step', 40, 'for last 250 steps:', 0.5325344812870025)\n",
      "('Average loss at step', 80, 'for last 250 steps:', 0.4382232815027237)\n",
      "('Average loss at step', 120, 'for last 250 steps:', 0.41487195730209353)\n",
      "('Average loss at step', 160, 'for last 250 steps:', 0.37303140938282014)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.32651673913002016)\n",
      "('Average loss at step', 240, 'for last 250 steps:', 0.2996251499652863)\n",
      "('Average loss at step', 280, 'for last 250 steps:', 0.2713623225688934)\n",
      "('Average loss at step', 320, 'for last 250 steps:', 0.25633897721767424)\n",
      "('Average loss at step', 360, 'for last 250 steps:', 0.2327279818058014)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.22611956983804704)\n",
      "('Average loss at step', 440, 'for last 250 steps:', 0.21668175041675566)\n",
      "('Average loss at step', 480, 'for last 250 steps:', 0.20703913301229476)\n",
      "('Average loss at step', 520, 'for last 250 steps:', 0.20386673718690873)\n",
      "('Average loss at step', 560, 'for last 250 steps:', 0.18333073377609252)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.17402555167675018)\n",
      "('Average loss at step', 640, 'for last 250 steps:', 0.18917196959257127)\n",
      "('Average loss at step', 680, 'for last 250 steps:', 0.16296235084533692)\n",
      "('Average loss at step', 720, 'for last 250 steps:', 0.17154906690120697)\n",
      "('Average loss at step', 760, 'for last 250 steps:', 0.15636586368083955)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.16149892866611482)\n",
      "('Average loss at step', 840, 'for last 250 steps:', 0.16362668335437774)\n",
      "('Average loss at step', 880, 'for last 250 steps:', 0.14713215574622154)\n",
      "('Average loss at step', 920, 'for last 250 steps:', 0.15436832427978517)\n",
      "('Average loss at step', 960, 'for last 250 steps:', 0.14654479533433915)\n",
      "('Average loss at step', 1000, 'for last 250 steps:', 0.1423199002444744)\n",
      "('Average loss at step', 1040, 'for last 250 steps:', 0.13603705108165742)\n",
      "('Average loss at step', 1080, 'for last 250 steps:', 0.1427058769762516)\n",
      "('Average loss at step', 1120, 'for last 250 steps:', 0.13770174756646156)\n",
      "('Average loss at step', 1160, 'for last 250 steps:', 0.13295672446489334)\n",
      "('Average loss at step', 1200, 'for last 250 steps:', 0.13083141282200814)\n",
      "('Average loss at step', 1240, 'for last 250 steps:', 0.12595270559191704)\n",
      "('Average loss at step', 1280, 'for last 250 steps:', 0.12951821848750114)\n",
      "('Average loss at step', 1320, 'for last 250 steps:', 0.12335704490542412)\n",
      "('Average loss at step', 1360, 'for last 250 steps:', 0.1285606199502945)\n",
      "('Average loss at step', 1400, 'for last 250 steps:', 0.12326497837901115)\n",
      "('Average loss at step', 1440, 'for last 250 steps:', 0.1220804999768734)\n",
      "('Average loss at step', 1480, 'for last 250 steps:', 0.11662244990468025)\n",
      "('Average loss at step', 1520, 'for last 250 steps:', 0.11956564262509346)\n",
      "('Average loss at step', 1560, 'for last 250 steps:', 0.12682389482855796)\n",
      "('Average loss at step', 1600, 'for last 250 steps:', 0.11704735517501831)\n",
      "('Average loss at step', 1640, 'for last 250 steps:', 0.10934787318110466)\n",
      "('Average loss at step', 1680, 'for last 250 steps:', 0.10877533376216889)\n",
      "('Average loss at step', 1720, 'for last 250 steps:', 0.1137541501224041)\n",
      "('Average loss at step', 1760, 'for last 250 steps:', 0.11605514526367187)\n",
      "('Average loss at step', 1800, 'for last 250 steps:', 0.11639913648366929)\n",
      "('Average loss at step', 1840, 'for last 250 steps:', 0.1112914077937603)\n",
      "('Average loss at step', 1880, 'for last 250 steps:', 0.10750471726059914)\n",
      "('Average loss at step', 1920, 'for last 250 steps:', 0.10540673956274986)\n",
      "('Average loss at step', 1960, 'for last 250 steps:', 0.1152334077656269)\n",
      "('Average loss at step', 2000, 'for last 250 steps:', 0.11179377898573875)\n",
      "('Average loss at step', 2040, 'for last 250 steps:', 0.10757249340415001)\n",
      "('Average loss at step', 2080, 'for last 250 steps:', 0.10842272624373436)\n",
      "('Average loss at step', 2120, 'for last 250 steps:', 0.10727367028594018)\n",
      "('Average loss at step', 2160, 'for last 250 steps:', 0.10519150488078594)\n",
      "('Average loss at step', 2200, 'for last 250 steps:', 0.10990888953208923)\n",
      "('Average loss at step', 2240, 'for last 250 steps:', 0.1035575595498085)\n",
      "('Average loss at step', 2280, 'for last 250 steps:', 0.10132581651210786)\n",
      "('Average loss at step', 2320, 'for last 250 steps:', 0.10400198347866535)\n",
      "('Average loss at step', 2360, 'for last 250 steps:', 0.10186499916017056)\n",
      "('Average loss at step', 2400, 'for last 250 steps:', 0.10114466100931167)\n",
      "('Average loss at step', 2440, 'for last 250 steps:', 0.10369078382849693)\n",
      "('Average loss at step', 2480, 'for last 250 steps:', 0.10415931820869445)\n",
      "('Average loss at step', 2520, 'for last 250 steps:', 0.10116635009646416)\n",
      "('Average loss at step', 2560, 'for last 250 steps:', 0.09734627120196819)\n",
      "('Average loss at step', 2600, 'for last 250 steps:', 0.09896882057189942)\n",
      "('Average loss at step', 2640, 'for last 250 steps:', 0.10140534371137619)\n",
      "('Average loss at step', 2680, 'for last 250 steps:', 0.09278717927634716)\n",
      "('Average loss at step', 2720, 'for last 250 steps:', 0.09554201573133468)\n",
      "('Average loss at step', 2760, 'for last 250 steps:', 0.10115253314375877)\n",
      "('Average loss at step', 2800, 'for last 250 steps:', 0.10235883809626102)\n",
      "('Average loss at step', 2840, 'for last 250 steps:', 0.09451277941465377)\n",
      "('Average loss at step', 2880, 'for last 250 steps:', 0.09863011166453362)\n",
      "('Average loss at step', 2920, 'for last 250 steps:', 0.09672962591052055)\n",
      "('Average loss at step', 2960, 'for last 250 steps:', 0.0898075544834137)\n",
      "('Average loss at step', 3000, 'for last 250 steps:', 0.09643685795366765)\n",
      "('Average loss at step', 3040, 'for last 250 steps:', 0.09283077746629714)\n",
      "('Average loss at step', 3080, 'for last 250 steps:', 0.0927620005607605)\n",
      "('Average loss at step', 3120, 'for last 250 steps:', 0.09603753805160523)\n",
      "('Average loss at step', 3160, 'for last 250 steps:', 0.10343906447291375)\n",
      "('Average loss at step', 3200, 'for last 250 steps:', 0.09533770367503167)\n",
      "('Average loss at step', 3240, 'for last 250 steps:', 0.09435449399054051)\n",
      "('Average loss at step', 3280, 'for last 250 steps:', 0.0968096512556076)\n",
      "('Average loss at step', 3320, 'for last 250 steps:', 0.09483008906245231)\n",
      "('Average loss at step', 3360, 'for last 250 steps:', 0.09397484049201012)\n",
      "('Average loss at step', 3400, 'for last 250 steps:', 0.08913660183548927)\n",
      "('Average loss at step', 3440, 'for last 250 steps:', 0.09006584271788597)\n",
      "('Average loss at step', 3480, 'for last 250 steps:', 0.09162611618638039)\n",
      "('Average loss at step', 3520, 'for last 250 steps:', 0.09118803717195988)\n",
      "('Average loss at step', 3560, 'for last 250 steps:', 0.09558435380458832)\n",
      "('Average loss at step', 3600, 'for last 250 steps:', 0.08399077080190182)\n",
      "('Average loss at step', 3640, 'for last 250 steps:', 0.08634236946702004)\n",
      "('Average loss at step', 3680, 'for last 250 steps:', 0.08791485764086246)\n",
      "('Average loss at step', 3720, 'for last 250 steps:', 0.08170063748955726)\n",
      "('Average loss at step', 3760, 'for last 250 steps:', 0.09272365339100361)\n",
      "('Average loss at step', 3800, 'for last 250 steps:', 0.09187004409730434)\n",
      "('Average loss at step', 3840, 'for last 250 steps:', 0.09048014618456364)\n",
      "('Average loss at step', 3880, 'for last 250 steps:', 0.08209680899977684)\n",
      "('Average loss at step', 3920, 'for last 250 steps:', 0.0930049815773964)\n",
      "('Average loss at step', 3960, 'for last 250 steps:', 0.08322354093194008)\n",
      "('\\nEPOCH', 1)\n",
      "('Average loss at step', 40, 'for last 250 steps:', 0.09145666562020778)\n",
      "('Average loss at step', 80, 'for last 250 steps:', 0.08699817098677158)\n",
      "('Average loss at step', 120, 'for last 250 steps:', 0.08958888128399849)\n",
      "('Average loss at step', 160, 'for last 250 steps:', 0.08444860942661762)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.08812728852033615)\n",
      "('Average loss at step', 240, 'for last 250 steps:', 0.08655144177377223)\n",
      "('Average loss at step', 280, 'for last 250 steps:', 0.08570534199476242)\n",
      "('Average loss at step', 320, 'for last 250 steps:', 0.0867795356363058)\n",
      "('Average loss at step', 360, 'for last 250 steps:', 0.0861939612030983)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.08916989415884018)\n",
      "('Average loss at step', 440, 'for last 250 steps:', 0.08585200019180775)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 480, 'for last 250 steps:', 0.08050698034465313)\n",
      "('Average loss at step', 520, 'for last 250 steps:', 0.07866134718060494)\n",
      "('Average loss at step', 560, 'for last 250 steps:', 0.08517490565776825)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.07722952298820018)\n",
      "('Average loss at step', 640, 'for last 250 steps:', 0.08367189131677151)\n",
      "('Average loss at step', 680, 'for last 250 steps:', 0.08017007529735565)\n",
      "('Average loss at step', 720, 'for last 250 steps:', 0.0846890876442194)\n",
      "('Average loss at step', 760, 'for last 250 steps:', 0.07849931813776494)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.08517688304185868)\n",
      "('Average loss at step', 840, 'for last 250 steps:', 0.07871231235563755)\n",
      "('Average loss at step', 880, 'for last 250 steps:', 0.08507458575069904)\n",
      "('Average loss at step', 920, 'for last 250 steps:', 0.08101630046963691)\n",
      "('Average loss at step', 960, 'for last 250 steps:', 0.07902063928544521)\n",
      "('Average loss at step', 1000, 'for last 250 steps:', 0.08328916922211647)\n",
      "('Average loss at step', 1040, 'for last 250 steps:', 0.08317644439637661)\n",
      "('Average loss at step', 1080, 'for last 250 steps:', 0.07899199642241)\n",
      "('Average loss at step', 1120, 'for last 250 steps:', 0.07934148512780666)\n",
      "('Average loss at step', 1160, 'for last 250 steps:', 0.08518046081066132)\n",
      "('Average loss at step', 1200, 'for last 250 steps:', 0.08804921910166741)\n",
      "('Average loss at step', 1240, 'for last 250 steps:', 0.08135777018964291)\n",
      "('Average loss at step', 1280, 'for last 250 steps:', 0.09252501606941223)\n",
      "('Average loss at step', 1320, 'for last 250 steps:', 0.07814852103590965)\n",
      "('Average loss at step', 1360, 'for last 250 steps:', 0.07917504914104939)\n",
      "('Average loss at step', 1400, 'for last 250 steps:', 0.08445089787244797)\n",
      "('Average loss at step', 1440, 'for last 250 steps:', 0.08197242349386215)\n",
      "('Average loss at step', 1480, 'for last 250 steps:', 0.07783214926719666)\n",
      "('Average loss at step', 1520, 'for last 250 steps:', 0.07670627549290657)\n",
      "('Average loss at step', 1560, 'for last 250 steps:', 0.08741526134312153)\n",
      "('Average loss at step', 1600, 'for last 250 steps:', 0.07878461323678493)\n",
      "('Average loss at step', 1640, 'for last 250 steps:', 0.0841866934299469)\n",
      "('Average loss at step', 1680, 'for last 250 steps:', 0.0712115790322423)\n",
      "('Average loss at step', 1720, 'for last 250 steps:', 0.08306743547320367)\n",
      "('Average loss at step', 1760, 'for last 250 steps:', 0.07980772919952869)\n",
      "('Average loss at step', 1800, 'for last 250 steps:', 0.07823760695755481)\n",
      "('Average loss at step', 1840, 'for last 250 steps:', 0.07774587456136942)\n",
      "('Average loss at step', 1880, 'for last 250 steps:', 0.07638284094631671)\n",
      "('Average loss at step', 1920, 'for last 250 steps:', 0.07606527261435986)\n",
      "('Average loss at step', 1960, 'for last 250 steps:', 0.079288774356246)\n",
      "('Average loss at step', 2000, 'for last 250 steps:', 0.08857992634177209)\n",
      "('Average loss at step', 2040, 'for last 250 steps:', 0.07539965957403183)\n",
      "('Average loss at step', 2080, 'for last 250 steps:', 0.075500298589468)\n",
      "('Average loss at step', 2120, 'for last 250 steps:', 0.08370532110333442)\n",
      "('Average loss at step', 2160, 'for last 250 steps:', 0.09055521003901959)\n",
      "('Average loss at step', 2200, 'for last 250 steps:', 0.07863905735313892)\n",
      "('Average loss at step', 2240, 'for last 250 steps:', 0.08125834904611111)\n",
      "('Average loss at step', 2280, 'for last 250 steps:', 0.08249875016510487)\n",
      "('Average loss at step', 2320, 'for last 250 steps:', 0.07444521069526672)\n",
      "('Average loss at step', 2360, 'for last 250 steps:', 0.0757767203450203)\n",
      "('Average loss at step', 2400, 'for last 250 steps:', 0.07589317731559277)\n",
      "('Average loss at step', 2440, 'for last 250 steps:', 0.07605531409382821)\n",
      "('Average loss at step', 2480, 'for last 250 steps:', 0.07849672921001911)\n",
      "('Average loss at step', 2520, 'for last 250 steps:', 0.07727351907640695)\n",
      "('Average loss at step', 2560, 'for last 250 steps:', 0.07365826666355133)\n",
      "('Average loss at step', 2600, 'for last 250 steps:', 0.07737380646169185)\n",
      "('Average loss at step', 2640, 'for last 250 steps:', 0.08149129666388034)\n",
      "('Average loss at step', 2680, 'for last 250 steps:', 0.07306458637118339)\n",
      "('Average loss at step', 2720, 'for last 250 steps:', 0.07377963364124299)\n",
      "('Average loss at step', 2760, 'for last 250 steps:', 0.08100672252476215)\n",
      "('Average loss at step', 2800, 'for last 250 steps:', 0.07314894132316113)\n",
      "('Average loss at step', 2840, 'for last 250 steps:', 0.07625732451677322)\n",
      "('Average loss at step', 2880, 'for last 250 steps:', 0.07585965238511562)\n",
      "('Average loss at step', 2920, 'for last 250 steps:', 0.07916893757879734)\n",
      "('Average loss at step', 2960, 'for last 250 steps:', 0.07252184227108956)\n",
      "('Average loss at step', 3000, 'for last 250 steps:', 0.07474674105644226)\n",
      "('Average loss at step', 3040, 'for last 250 steps:', 0.07437802977859974)\n",
      "('Average loss at step', 3080, 'for last 250 steps:', 0.07153155371546745)\n",
      "('Average loss at step', 3120, 'for last 250 steps:', 0.07194975353777408)\n",
      "('Average loss at step', 3160, 'for last 250 steps:', 0.0723896662145853)\n",
      "('Average loss at step', 3200, 'for last 250 steps:', 0.07032217144966126)\n",
      "('Average loss at step', 3240, 'for last 250 steps:', 0.07498683754354715)\n",
      "('Average loss at step', 3280, 'for last 250 steps:', 0.07122674770653248)\n",
      "('Average loss at step', 3320, 'for last 250 steps:', 0.08302962712943554)\n",
      "('Average loss at step', 3360, 'for last 250 steps:', 0.07607781294733286)\n",
      "('Average loss at step', 3400, 'for last 250 steps:', 0.07640658512711525)\n",
      "('Average loss at step', 3440, 'for last 250 steps:', 0.07261242970824242)\n",
      "('Average loss at step', 3480, 'for last 250 steps:', 0.07665102213621139)\n",
      "('Average loss at step', 3520, 'for last 250 steps:', 0.07241728350520134)\n",
      "('Average loss at step', 3560, 'for last 250 steps:', 0.07839384317398071)\n",
      "('Average loss at step', 3600, 'for last 250 steps:', 0.09068335585296154)\n",
      "('Average loss at step', 3640, 'for last 250 steps:', 0.06913520678877831)\n",
      "('Average loss at step', 3680, 'for last 250 steps:', 0.07492433071136474)\n",
      "('Average loss at step', 3720, 'for last 250 steps:', 0.06541927605867386)\n",
      "('Average loss at step', 3760, 'for last 250 steps:', 0.07936579190194606)\n",
      "('Average loss at step', 3800, 'for last 250 steps:', 0.0817437107861042)\n",
      "('Average loss at step', 3840, 'for last 250 steps:', 0.07711376741528511)\n",
      "('Average loss at step', 3880, 'for last 250 steps:', 0.06884274799376726)\n",
      "('Average loss at step', 3920, 'for last 250 steps:', 0.07427391044795513)\n",
      "('Average loss at step', 3960, 'for last 250 steps:', 0.07358920253813267)\n",
      "('\\nEPOCH', 2)\n",
      "('Average loss at step', 40, 'for last 250 steps:', 0.0757918281853199)\n",
      "('Average loss at step', 80, 'for last 250 steps:', 0.07367884956300258)\n",
      "('Average loss at step', 120, 'for last 250 steps:', 0.07176886476576329)\n",
      "('Average loss at step', 160, 'for last 250 steps:', 0.07408401109278202)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.07266755394637585)\n",
      "('Average loss at step', 240, 'for last 250 steps:', 0.07903246611356735)\n",
      "('Average loss at step', 280, 'for last 250 steps:', 0.06649583742022515)\n",
      "('Average loss at step', 320, 'for last 250 steps:', 0.07106392368674279)\n",
      "('Average loss at step', 360, 'for last 250 steps:', 0.07521127238869667)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.07234210647642612)\n",
      "('Average loss at step', 440, 'for last 250 steps:', 0.07089544765651226)\n",
      "('Average loss at step', 480, 'for last 250 steps:', 0.07689853169023991)\n",
      "('Average loss at step', 520, 'for last 250 steps:', 0.07354437373578548)\n",
      "('Average loss at step', 560, 'for last 250 steps:', 0.07383215241134167)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.0684195427596569)\n",
      "('Average loss at step', 640, 'for last 250 steps:', 0.07461270920932293)\n",
      "('Average loss at step', 680, 'for last 250 steps:', 0.0739507558196783)\n",
      "('Average loss at step', 720, 'for last 250 steps:', 0.07626667998731136)\n",
      "('Average loss at step', 760, 'for last 250 steps:', 0.0657496703416109)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.07276200346648692)\n",
      "('Average loss at step', 840, 'for last 250 steps:', 0.07422568432986737)\n",
      "('Average loss at step', 880, 'for last 250 steps:', 0.0711438887566328)\n",
      "('Average loss at step', 920, 'for last 250 steps:', 0.07084187403321267)\n",
      "('Average loss at step', 960, 'for last 250 steps:', 0.06635405607521534)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 1000, 'for last 250 steps:', 0.06770276326686143)\n",
      "('Average loss at step', 1040, 'for last 250 steps:', 0.06513030283153057)\n",
      "('Average loss at step', 1080, 'for last 250 steps:', 0.06119546055793762)\n",
      "('Average loss at step', 1120, 'for last 250 steps:', 0.07463228292763233)\n",
      "('Average loss at step', 1160, 'for last 250 steps:', 0.067016611546278)\n",
      "('Average loss at step', 1200, 'for last 250 steps:', 0.06894581973552703)\n",
      "('Average loss at step', 1240, 'for last 250 steps:', 0.0690011727809906)\n",
      "('Average loss at step', 1280, 'for last 250 steps:', 0.07562428414821624)\n",
      "('Average loss at step', 1320, 'for last 250 steps:', 0.07278162993490696)\n",
      "('Average loss at step', 1360, 'for last 250 steps:', 0.06869991667568684)\n",
      "('Average loss at step', 1400, 'for last 250 steps:', 0.07516860913485289)\n",
      "('Average loss at step', 1440, 'for last 250 steps:', 0.07095152497291565)\n",
      "('Average loss at step', 1480, 'for last 250 steps:', 0.06504515014588833)\n",
      "('Average loss at step', 1520, 'for last 250 steps:', 0.06960427269339561)\n",
      "('Average loss at step', 1560, 'for last 250 steps:', 0.07269278146326542)\n",
      "('Average loss at step', 1600, 'for last 250 steps:', 0.07368886195123196)\n",
      "('Average loss at step', 1640, 'for last 250 steps:', 0.06696863090619445)\n",
      "('Average loss at step', 1680, 'for last 250 steps:', 0.06920711614191533)\n",
      "('Average loss at step', 1720, 'for last 250 steps:', 0.06463044807314873)\n",
      "('Average loss at step', 1760, 'for last 250 steps:', 0.06737989708781242)\n",
      "('Average loss at step', 1800, 'for last 250 steps:', 0.06775401636958123)\n",
      "('Average loss at step', 1840, 'for last 250 steps:', 0.06644355662167073)\n",
      "('Average loss at step', 1880, 'for last 250 steps:', 0.07097449399530888)\n",
      "('Average loss at step', 1920, 'for last 250 steps:', 0.07726907841861248)\n",
      "('Average loss at step', 1960, 'for last 250 steps:', 0.0679581281542778)\n",
      "('Average loss at step', 2000, 'for last 250 steps:', 0.0716675017029047)\n",
      "('Average loss at step', 2040, 'for last 250 steps:', 0.07303247548639774)\n",
      "('Average loss at step', 2080, 'for last 250 steps:', 0.06200337663292885)\n",
      "('Average loss at step', 2120, 'for last 250 steps:', 0.07144253820180893)\n",
      "('Average loss at step', 2160, 'for last 250 steps:', 0.07030740775167942)\n",
      "('Average loss at step', 2200, 'for last 250 steps:', 0.06992563288658857)\n",
      "('Average loss at step', 2240, 'for last 250 steps:', 0.06907160121947527)\n",
      "('Average loss at step', 2280, 'for last 250 steps:', 0.06704570714384317)\n",
      "('Average loss at step', 2320, 'for last 250 steps:', 0.06770703695714474)\n",
      "('Average loss at step', 2360, 'for last 250 steps:', 0.06601582244038581)\n",
      "('Average loss at step', 2400, 'for last 250 steps:', 0.06790118128061294)\n",
      "('Average loss at step', 2440, 'for last 250 steps:', 0.06651685073971748)\n",
      "('Average loss at step', 2480, 'for last 250 steps:', 0.0654044022038579)\n",
      "('Average loss at step', 2520, 'for last 250 steps:', 0.05954042412340641)\n",
      "('Average loss at step', 2560, 'for last 250 steps:', 0.07061052352190017)\n",
      "('Average loss at step', 2600, 'for last 250 steps:', 0.07715339444577694)\n",
      "('Average loss at step', 2640, 'for last 250 steps:', 0.06581994257867337)\n",
      "('Average loss at step', 2680, 'for last 250 steps:', 0.06824188686907291)\n",
      "('Average loss at step', 2720, 'for last 250 steps:', 0.07140639513731002)\n",
      "('Average loss at step', 2760, 'for last 250 steps:', 0.0677200885862112)\n",
      "('Average loss at step', 2800, 'for last 250 steps:', 0.06388082608580589)\n",
      "('Average loss at step', 2840, 'for last 250 steps:', 0.06394127611070871)\n",
      "('Average loss at step', 2880, 'for last 250 steps:', 0.06740721799433232)\n",
      "('Average loss at step', 2920, 'for last 250 steps:', 0.07591716378927231)\n",
      "('Average loss at step', 2960, 'for last 250 steps:', 0.06740658301860095)\n",
      "('Average loss at step', 3000, 'for last 250 steps:', 0.0696235553920269)\n",
      "('Average loss at step', 3040, 'for last 250 steps:', 0.07524015299975872)\n",
      "('Average loss at step', 3080, 'for last 250 steps:', 0.06518208459019662)\n",
      "('Average loss at step', 3120, 'for last 250 steps:', 0.06468938775360585)\n",
      "('Average loss at step', 3160, 'for last 250 steps:', 0.07455264143645764)\n",
      "('Average loss at step', 3200, 'for last 250 steps:', 0.07524339586496354)\n",
      "('Average loss at step', 3240, 'for last 250 steps:', 0.07067967016249894)\n",
      "('Average loss at step', 3280, 'for last 250 steps:', 0.06987586170434952)\n",
      "('Average loss at step', 3320, 'for last 250 steps:', 0.06732182048261165)\n",
      "('Average loss at step', 3360, 'for last 250 steps:', 0.06894549161195755)\n",
      "('Average loss at step', 3400, 'for last 250 steps:', 0.07326908595860004)\n",
      "('Average loss at step', 3440, 'for last 250 steps:', 0.0674015187099576)\n",
      "('Average loss at step', 3480, 'for last 250 steps:', 0.06603504598140716)\n",
      "('Average loss at step', 3520, 'for last 250 steps:', 0.06604656133800745)\n",
      "('Average loss at step', 3560, 'for last 250 steps:', 0.0687313862144947)\n",
      "('Average loss at step', 3600, 'for last 250 steps:', 0.06444912776350975)\n",
      "('Average loss at step', 3640, 'for last 250 steps:', 0.06697016969323158)\n",
      "('Average loss at step', 3680, 'for last 250 steps:', 0.060878845043480394)\n",
      "('Average loss at step', 3720, 'for last 250 steps:', 0.06998630851507187)\n",
      "('Average loss at step', 3760, 'for last 250 steps:', 0.06041005313396454)\n",
      "('Average loss at step', 3800, 'for last 250 steps:', 0.06373713202774525)\n",
      "('Average loss at step', 3840, 'for last 250 steps:', 0.05892713025212288)\n",
      "('Average loss at step', 3880, 'for last 250 steps:', 0.05537192694842816)\n",
      "('Average loss at step', 3920, 'for last 250 steps:', 0.06551724441349506)\n",
      "('Average loss at step', 3960, 'for last 250 steps:', 0.0648979153484106)\n",
      "('\\nEPOCH', 3)\n",
      "('Average loss at step', 40, 'for last 250 steps:', 0.06498338907957077)\n",
      "('Average loss at step', 80, 'for last 250 steps:', 0.06972415022552013)\n",
      "('Average loss at step', 120, 'for last 250 steps:', 0.07260069079697132)\n",
      "('Average loss at step', 160, 'for last 250 steps:', 0.07286882445216179)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.06742519438266754)\n",
      "('Average loss at step', 240, 'for last 250 steps:', 0.06512675449252128)\n",
      "('Average loss at step', 280, 'for last 250 steps:', 0.06343261234462261)\n",
      "('Average loss at step', 320, 'for last 250 steps:', 0.06970579504966735)\n",
      "('Average loss at step', 360, 'for last 250 steps:', 0.06225450716912746)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.07045643545687198)\n",
      "('Average loss at step', 440, 'for last 250 steps:', 0.06029909171164036)\n",
      "('Average loss at step', 480, 'for last 250 steps:', 0.07493231073021889)\n",
      "('Average loss at step', 520, 'for last 250 steps:', 0.05945502277463675)\n",
      "('Average loss at step', 560, 'for last 250 steps:', 0.058250552229583266)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.06116696044802666)\n",
      "('Average loss at step', 640, 'for last 250 steps:', 0.06956973254680633)\n",
      "('Average loss at step', 680, 'for last 250 steps:', 0.06198339678347111)\n",
      "('Average loss at step', 720, 'for last 250 steps:', 0.05880332257598639)\n",
      "('Average loss at step', 760, 'for last 250 steps:', 0.068668880648911)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.06728012971580029)\n",
      "('Average loss at step', 840, 'for last 250 steps:', 0.06654261380434036)\n",
      "('Average loss at step', 880, 'for last 250 steps:', 0.06529169410467148)\n",
      "('Average loss at step', 920, 'for last 250 steps:', 0.06187081888318062)\n",
      "('Average loss at step', 960, 'for last 250 steps:', 0.06366859901696444)\n",
      "('Average loss at step', 1000, 'for last 250 steps:', 0.05632729858160019)\n",
      "('Average loss at step', 1040, 'for last 250 steps:', 0.06646973736584187)\n",
      "('Average loss at step', 1080, 'for last 250 steps:', 0.0649563205242157)\n",
      "('Average loss at step', 1120, 'for last 250 steps:', 0.07055430464446545)\n",
      "('Average loss at step', 1160, 'for last 250 steps:', 0.0661526744812727)\n",
      "('Average loss at step', 1200, 'for last 250 steps:', 0.06955170661211013)\n",
      "('Average loss at step', 1240, 'for last 250 steps:', 0.06636722441762685)\n",
      "('Average loss at step', 1280, 'for last 250 steps:', 0.0643170502781868)\n",
      "('Average loss at step', 1320, 'for last 250 steps:', 0.06454042196273804)\n",
      "('Average loss at step', 1360, 'for last 250 steps:', 0.06408118441700936)\n",
      "('Average loss at step', 1400, 'for last 250 steps:', 0.06499386571347714)\n",
      "('Average loss at step', 1440, 'for last 250 steps:', 0.060649586506187916)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 1480, 'for last 250 steps:', 0.06156477205455303)\n",
      "('Average loss at step', 1520, 'for last 250 steps:', 0.059479803144931793)\n",
      "('Average loss at step', 1560, 'for last 250 steps:', 0.07220002844929695)\n",
      "('Average loss at step', 1600, 'for last 250 steps:', 0.06105424460023642)\n",
      "('Average loss at step', 1640, 'for last 250 steps:', 0.059496281892061235)\n",
      "('Average loss at step', 1680, 'for last 250 steps:', 0.07077763963490724)\n",
      "('Average loss at step', 1720, 'for last 250 steps:', 0.05448203768581152)\n",
      "('Average loss at step', 1760, 'for last 250 steps:', 0.05989430163055658)\n",
      "('Average loss at step', 1800, 'for last 250 steps:', 0.06134968087077141)\n",
      "('Average loss at step', 1840, 'for last 250 steps:', 0.06563509624451398)\n",
      "('Average loss at step', 1880, 'for last 250 steps:', 0.06048457957804203)\n",
      "('Average loss at step', 1920, 'for last 250 steps:', 0.06363281890749932)\n",
      "('Average loss at step', 1960, 'for last 250 steps:', 0.06516878068447113)\n",
      "('Average loss at step', 2000, 'for last 250 steps:', 0.0611847073584795)\n",
      "('Average loss at step', 2040, 'for last 250 steps:', 0.062313557006418704)\n",
      "('Average loss at step', 2080, 'for last 250 steps:', 0.0651782901585102)\n",
      "('Average loss at step', 2120, 'for last 250 steps:', 0.06053940251469612)\n",
      "('Average loss at step', 2160, 'for last 250 steps:', 0.06188812874257565)\n",
      "('Average loss at step', 2200, 'for last 250 steps:', 0.06547170899808406)\n",
      "('Average loss at step', 2240, 'for last 250 steps:', 0.06653884880244731)\n",
      "('Average loss at step', 2280, 'for last 250 steps:', 0.0652023658901453)\n",
      "('Average loss at step', 2320, 'for last 250 steps:', 0.06774498011916875)\n",
      "('Average loss at step', 2360, 'for last 250 steps:', 0.06365488186478614)\n",
      "('Average loss at step', 2400, 'for last 250 steps:', 0.061811842508614066)\n",
      "('Average loss at step', 2440, 'for last 250 steps:', 0.06405153159052134)\n",
      "('Average loss at step', 2480, 'for last 250 steps:', 0.06509409576654435)\n",
      "('Average loss at step', 2520, 'for last 250 steps:', 0.06182292357087135)\n",
      "('Average loss at step', 2560, 'for last 250 steps:', 0.06636120405048132)\n",
      "('Average loss at step', 2600, 'for last 250 steps:', 0.06528949238359928)\n",
      "('Average loss at step', 2640, 'for last 250 steps:', 0.06593535929918289)\n",
      "('Average loss at step', 2680, 'for last 250 steps:', 0.07540316354483366)\n",
      "('Average loss at step', 2720, 'for last 250 steps:', 0.059856656789779666)\n",
      "('Average loss at step', 2760, 'for last 250 steps:', 0.06477878425270318)\n",
      "('Average loss at step', 2800, 'for last 250 steps:', 0.0647512898594141)\n",
      "('Average loss at step', 2840, 'for last 250 steps:', 0.06508684121072292)\n",
      "('Average loss at step', 2880, 'for last 250 steps:', 0.06373696558177472)\n",
      "('Average loss at step', 2920, 'for last 250 steps:', 0.06305414110422135)\n",
      "('Average loss at step', 2960, 'for last 250 steps:', 0.0673419488966465)\n",
      "('Average loss at step', 3000, 'for last 250 steps:', 0.0670416859537363)\n",
      "('Average loss at step', 3040, 'for last 250 steps:', 0.05798695631325245)\n",
      "('Average loss at step', 3080, 'for last 250 steps:', 0.06435545936226844)\n",
      "('Average loss at step', 3120, 'for last 250 steps:', 0.05985901352018118)\n",
      "('Average loss at step', 3160, 'for last 250 steps:', 0.06188799221068621)\n",
      "('Average loss at step', 3200, 'for last 250 steps:', 0.06401273339986802)\n",
      "('Average loss at step', 3240, 'for last 250 steps:', 0.05803218387067318)\n",
      "('Average loss at step', 3280, 'for last 250 steps:', 0.06282894946634769)\n",
      "('Average loss at step', 3320, 'for last 250 steps:', 0.0640315148420632)\n",
      "('Average loss at step', 3360, 'for last 250 steps:', 0.061182943284511564)\n",
      "('Average loss at step', 3400, 'for last 250 steps:', 0.06466710351407529)\n",
      "('Average loss at step', 3440, 'for last 250 steps:', 0.06605221133679151)\n",
      "('Average loss at step', 3480, 'for last 250 steps:', 0.05280485920608044)\n",
      "('Average loss at step', 3520, 'for last 250 steps:', 0.06545843675732613)\n",
      "('Average loss at step', 3560, 'for last 250 steps:', 0.05985294789075851)\n",
      "('Average loss at step', 3600, 'for last 250 steps:', 0.06502892188727856)\n",
      "('Average loss at step', 3640, 'for last 250 steps:', 0.06285071384161711)\n",
      "('Average loss at step', 3680, 'for last 250 steps:', 0.05936385277658701)\n",
      "('Average loss at step', 3720, 'for last 250 steps:', 0.06104823365807533)\n",
      "('Average loss at step', 3760, 'for last 250 steps:', 0.06291689075529576)\n",
      "('Average loss at step', 3800, 'for last 250 steps:', 0.06040018226951361)\n",
      "('Average loss at step', 3840, 'for last 250 steps:', 0.05833708852529526)\n",
      "('Average loss at step', 3880, 'for last 250 steps:', 0.053100142441689965)\n",
      "('Average loss at step', 3920, 'for last 250 steps:', 0.06198147255927324)\n",
      "('Average loss at step', 3960, 'for last 250 steps:', 0.06531444534659386)\n",
      "('\\nEPOCH', 4)\n",
      "('Average loss at step', 40, 'for last 250 steps:', 0.06128037728369236)\n",
      "('Average loss at step', 80, 'for last 250 steps:', 0.062469368353486064)\n",
      "('Average loss at step', 120, 'for last 250 steps:', 0.06583904579281807)\n",
      "('Average loss at step', 160, 'for last 250 steps:', 0.059767828099429605)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.0705675233900547)\n",
      "('Average loss at step', 240, 'for last 250 steps:', 0.06233154609799385)\n",
      "('Average loss at step', 280, 'for last 250 steps:', 0.06269709154963493)\n",
      "('Average loss at step', 320, 'for last 250 steps:', 0.07382326751947403)\n",
      "('Average loss at step', 360, 'for last 250 steps:', 0.06252014931291341)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.06704679615795613)\n",
      "('Average loss at step', 440, 'for last 250 steps:', 0.06145017929375172)\n",
      "('Average loss at step', 480, 'for last 250 steps:', 0.0656550569087267)\n",
      "('Average loss at step', 520, 'for last 250 steps:', 0.06282695353031159)\n",
      "('Average loss at step', 560, 'for last 250 steps:', 0.059821038730442526)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.05573561977595091)\n",
      "('Average loss at step', 640, 'for last 250 steps:', 0.05432109724730253)\n",
      "('Average loss at step', 680, 'for last 250 steps:', 0.060274429768323895)\n",
      "('Average loss at step', 720, 'for last 250 steps:', 0.06382433965802192)\n",
      "('Average loss at step', 760, 'for last 250 steps:', 0.0617056230455637)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.05858279276639223)\n",
      "('Average loss at step', 840, 'for last 250 steps:', 0.06381423871964216)\n",
      "('Average loss at step', 880, 'for last 250 steps:', 0.059111458882689476)\n",
      "('Average loss at step', 920, 'for last 250 steps:', 0.06624518621712923)\n",
      "('Average loss at step', 960, 'for last 250 steps:', 0.057263357751071456)\n",
      "('Average loss at step', 1000, 'for last 250 steps:', 0.056372939981520175)\n",
      "('Average loss at step', 1040, 'for last 250 steps:', 0.06185574691742659)\n",
      "('Average loss at step', 1080, 'for last 250 steps:', 0.05558133982121945)\n",
      "('Average loss at step', 1120, 'for last 250 steps:', 0.061568808183073996)\n",
      "('Average loss at step', 1160, 'for last 250 steps:', 0.061020635440945624)\n",
      "('Average loss at step', 1200, 'for last 250 steps:', 0.06395539995282888)\n",
      "('Average loss at step', 1240, 'for last 250 steps:', 0.05441845916211605)\n",
      "('Average loss at step', 1280, 'for last 250 steps:', 0.06448850486427546)\n",
      "('Average loss at step', 1320, 'for last 250 steps:', 0.05936038296669722)\n",
      "('Average loss at step', 1360, 'for last 250 steps:', 0.06743806108832359)\n",
      "('Average loss at step', 1400, 'for last 250 steps:', 0.060281999856233594)\n",
      "('Average loss at step', 1440, 'for last 250 steps:', 0.05374146580696106)\n",
      "('Average loss at step', 1480, 'for last 250 steps:', 0.059424338787794115)\n",
      "('Average loss at step', 1520, 'for last 250 steps:', 0.05889466136693954)\n",
      "('Average loss at step', 1560, 'for last 250 steps:', 0.061607455089688304)\n",
      "('Average loss at step', 1600, 'for last 250 steps:', 0.05957825765013695)\n",
      "('Average loss at step', 1640, 'for last 250 steps:', 0.06024391438812018)\n",
      "('Average loss at step', 1680, 'for last 250 steps:', 0.06051056008785963)\n",
      "('Average loss at step', 1720, 'for last 250 steps:', 0.051373706012964246)\n",
      "('Average loss at step', 1760, 'for last 250 steps:', 0.05814106460660696)\n",
      "('Average loss at step', 1800, 'for last 250 steps:', 0.055563724413514134)\n",
      "('Average loss at step', 1840, 'for last 250 steps:', 0.05986677549779415)\n",
      "('Average loss at step', 1880, 'for last 250 steps:', 0.07127495631575584)\n",
      "('Average loss at step', 1920, 'for last 250 steps:', 0.06321470912545919)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 1960, 'for last 250 steps:', 0.05871973197907209)\n",
      "('Average loss at step', 2000, 'for last 250 steps:', 0.06738993890583515)\n",
      "('Average loss at step', 2040, 'for last 250 steps:', 0.06304577499628067)\n",
      "('Average loss at step', 2080, 'for last 250 steps:', 0.05571371525526047)\n",
      "('Average loss at step', 2120, 'for last 250 steps:', 0.062369270399212834)\n",
      "('Average loss at step', 2160, 'for last 250 steps:', 0.061530077159404756)\n",
      "('Average loss at step', 2200, 'for last 250 steps:', 0.052694691345095634)\n",
      "('Average loss at step', 2240, 'for last 250 steps:', 0.06020082019269466)\n",
      "('Average loss at step', 2280, 'for last 250 steps:', 0.0578883333131671)\n",
      "('Average loss at step', 2320, 'for last 250 steps:', 0.05733067374676466)\n",
      "('Average loss at step', 2360, 'for last 250 steps:', 0.06081079185009003)\n",
      "('Average loss at step', 2400, 'for last 250 steps:', 0.060591468289494514)\n",
      "('Average loss at step', 2440, 'for last 250 steps:', 0.06213688313961029)\n",
      "('Average loss at step', 2480, 'for last 250 steps:', 0.061918413266539574)\n",
      "('Average loss at step', 2520, 'for last 250 steps:', 0.05976545162498951)\n",
      "('Average loss at step', 2560, 'for last 250 steps:', 0.06455509759485721)\n",
      "('Average loss at step', 2600, 'for last 250 steps:', 0.06395142778754234)\n",
      "('Average loss at step', 2640, 'for last 250 steps:', 0.05724298186600208)\n",
      "('Average loss at step', 2680, 'for last 250 steps:', 0.05740418653935194)\n",
      "('Average loss at step', 2720, 'for last 250 steps:', 0.06444919534027577)\n",
      "('Average loss at step', 2760, 'for last 250 steps:', 0.05467592783272266)\n",
      "('Average loss at step', 2800, 'for last 250 steps:', 0.0624723201431334)\n",
      "('Average loss at step', 2840, 'for last 250 steps:', 0.055000869166105984)\n",
      "('Average loss at step', 2880, 'for last 250 steps:', 0.0590459805354476)\n",
      "('Average loss at step', 2920, 'for last 250 steps:', 0.06081002905964852)\n",
      "('Average loss at step', 2960, 'for last 250 steps:', 0.05468637712299824)\n",
      "('Average loss at step', 3000, 'for last 250 steps:', 0.058171646296978)\n",
      "('Average loss at step', 3040, 'for last 250 steps:', 0.054861427508294584)\n",
      "('Average loss at step', 3080, 'for last 250 steps:', 0.05962834753096104)\n",
      "('Average loss at step', 3120, 'for last 250 steps:', 0.055486461296677586)\n",
      "('Average loss at step', 3160, 'for last 250 steps:', 0.061801498979330065)\n",
      "('Average loss at step', 3200, 'for last 250 steps:', 0.06270321048796176)\n",
      "('Average loss at step', 3240, 'for last 250 steps:', 0.0646062245965004)\n",
      "('Average loss at step', 3280, 'for last 250 steps:', 0.059494756534695624)\n",
      "('Average loss at step', 3320, 'for last 250 steps:', 0.056419828124344346)\n",
      "('Average loss at step', 3360, 'for last 250 steps:', 0.06118730142712593)\n",
      "('Average loss at step', 3400, 'for last 250 steps:', 0.06028682954609394)\n",
      "('Average loss at step', 3440, 'for last 250 steps:', 0.05681128591299057)\n",
      "('Average loss at step', 3480, 'for last 250 steps:', 0.05606833331286907)\n",
      "('Average loss at step', 3520, 'for last 250 steps:', 0.06285033248364925)\n",
      "('Average loss at step', 3560, 'for last 250 steps:', 0.05876485202461481)\n",
      "('Average loss at step', 3600, 'for last 250 steps:', 0.05605041977018118)\n",
      "('Average loss at step', 3640, 'for last 250 steps:', 0.05660369642078877)\n",
      "('Average loss at step', 3680, 'for last 250 steps:', 0.056615155413746836)\n",
      "('Average loss at step', 3720, 'for last 250 steps:', 0.06133890606462956)\n",
      "('Average loss at step', 3760, 'for last 250 steps:', 0.05509925853461027)\n",
      "('Average loss at step', 3800, 'for last 250 steps:', 0.0597455583512783)\n",
      "('Average loss at step', 3840, 'for last 250 steps:', 0.05914337694644928)\n",
      "('Average loss at step', 3880, 'for last 250 steps:', 0.05972100451588631)\n",
      "('Average loss at step', 3920, 'for last 250 steps:', 0.05142365023493767)\n",
      "('Average loss at step', 3960, 'for last 250 steps:', 0.06517738457769155)\n",
      "('\\nEPOCH', 5)\n",
      "('Average loss at step', 40, 'for last 250 steps:', 0.07019622705876827)\n",
      "('Average loss at step', 80, 'for last 250 steps:', 0.05670041188597679)\n",
      "('Average loss at step', 120, 'for last 250 steps:', 0.061664185114204885)\n",
      "('Average loss at step', 160, 'for last 250 steps:', 0.05736307844519615)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.06781042255461216)\n",
      "('Average loss at step', 240, 'for last 250 steps:', 0.05942883029580116)\n",
      "('Average loss at step', 280, 'for last 250 steps:', 0.06158173732459545)\n",
      "('Average loss at step', 320, 'for last 250 steps:', 0.05972545772790909)\n",
      "('Average loss at step', 360, 'for last 250 steps:', 0.06332336898893118)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.05399483554065228)\n",
      "('Average loss at step', 440, 'for last 250 steps:', 0.05918655581772327)\n",
      "('Average loss at step', 480, 'for last 250 steps:', 0.06154242530465126)\n",
      "('Average loss at step', 520, 'for last 250 steps:', 0.05923351220786571)\n",
      "('Average loss at step', 560, 'for last 250 steps:', 0.058522830307483675)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.05985364258289337)\n",
      "('Average loss at step', 640, 'for last 250 steps:', 0.06761743534356356)\n",
      "('Average loss at step', 680, 'for last 250 steps:', 0.05752905167639256)\n",
      "('Average loss at step', 720, 'for last 250 steps:', 0.06148544568568468)\n",
      "('Average loss at step', 760, 'for last 250 steps:', 0.0607580129057169)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.057012012079358104)\n",
      "('Average loss at step', 840, 'for last 250 steps:', 0.05572486467659474)\n",
      "('Average loss at step', 880, 'for last 250 steps:', 0.05691184833645821)\n",
      "('Average loss at step', 920, 'for last 250 steps:', 0.05698283065110445)\n",
      "('Average loss at step', 960, 'for last 250 steps:', 0.053432529978454116)\n",
      "('Average loss at step', 1000, 'for last 250 steps:', 0.06068940432742238)\n",
      "('Average loss at step', 1040, 'for last 250 steps:', 0.05323330260813236)\n",
      "('Average loss at step', 1080, 'for last 250 steps:', 0.057505765780806545)\n",
      "('Average loss at step', 1120, 'for last 250 steps:', 0.05580632291734219)\n",
      "('Average loss at step', 1160, 'for last 250 steps:', 0.0565894041582942)\n",
      "('Average loss at step', 1200, 'for last 250 steps:', 0.061162147372961044)\n",
      "('Average loss at step', 1240, 'for last 250 steps:', 0.0547714114189148)\n",
      "('Average loss at step', 1280, 'for last 250 steps:', 0.05703527886420488)\n",
      "('Average loss at step', 1320, 'for last 250 steps:', 0.05579275593161583)\n",
      "('Average loss at step', 1360, 'for last 250 steps:', 0.056273845545947554)\n",
      "('Average loss at step', 1400, 'for last 250 steps:', 0.05247694462537766)\n",
      "('Average loss at step', 1440, 'for last 250 steps:', 0.04985230185091496)\n",
      "('Average loss at step', 1480, 'for last 250 steps:', 0.05551132008433342)\n",
      "('Average loss at step', 1520, 'for last 250 steps:', 0.055014519058167934)\n",
      "('Average loss at step', 1560, 'for last 250 steps:', 0.0633296275138855)\n",
      "('Average loss at step', 1600, 'for last 250 steps:', 0.05574555160477757)\n",
      "('Average loss at step', 1640, 'for last 250 steps:', 0.05313877008855343)\n",
      "('Average loss at step', 1680, 'for last 250 steps:', 0.05642587054520845)\n",
      "('Average loss at step', 1720, 'for last 250 steps:', 0.05482135929167271)\n",
      "('Average loss at step', 1760, 'for last 250 steps:', 0.054644314646720885)\n",
      "('Average loss at step', 1800, 'for last 250 steps:', 0.055047614052891734)\n",
      "('Average loss at step', 1840, 'for last 250 steps:', 0.05374177861958742)\n",
      "('Average loss at step', 1880, 'for last 250 steps:', 0.05801909208297729)\n",
      "('Average loss at step', 1920, 'for last 250 steps:', 0.05936726130545139)\n",
      "('Average loss at step', 1960, 'for last 250 steps:', 0.046038418374955654)\n",
      "('Average loss at step', 2000, 'for last 250 steps:', 0.06122371226549148)\n",
      "('Average loss at step', 2040, 'for last 250 steps:', 0.06069617912173271)\n",
      "('Average loss at step', 2080, 'for last 250 steps:', 0.0591179296374321)\n",
      "('Average loss at step', 2120, 'for last 250 steps:', 0.06315513648092747)\n",
      "('Average loss at step', 2160, 'for last 250 steps:', 0.06189419515430927)\n",
      "('Average loss at step', 2200, 'for last 250 steps:', 0.06312803268432617)\n",
      "('Average loss at step', 2240, 'for last 250 steps:', 0.057146843932569025)\n",
      "('Average loss at step', 2280, 'for last 250 steps:', 0.05666453689336777)\n",
      "('Average loss at step', 2320, 'for last 250 steps:', 0.05516168620437384)\n",
      "('Average loss at step', 2360, 'for last 250 steps:', 0.06403589084744453)\n",
      "('Average loss at step', 2400, 'for last 250 steps:', 0.05752844009548426)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 2440, 'for last 250 steps:', 0.05457514949142933)\n",
      "('Average loss at step', 2480, 'for last 250 steps:', 0.05513036657124758)\n",
      "('Average loss at step', 2520, 'for last 250 steps:', 0.049313885569572447)\n",
      "('Average loss at step', 2560, 'for last 250 steps:', 0.05448789667338133)\n",
      "('Average loss at step', 2600, 'for last 250 steps:', 0.051489553041756154)\n",
      "('Average loss at step', 2640, 'for last 250 steps:', 0.05532611943781376)\n",
      "('Average loss at step', 2680, 'for last 250 steps:', 0.0629106929153204)\n",
      "('Average loss at step', 2720, 'for last 250 steps:', 0.05197285626083612)\n",
      "('Average loss at step', 2760, 'for last 250 steps:', 0.06005380600690842)\n",
      "('Average loss at step', 2800, 'for last 250 steps:', 0.056512660533189776)\n",
      "('Average loss at step', 2840, 'for last 250 steps:', 0.051266723535954954)\n",
      "('Average loss at step', 2880, 'for last 250 steps:', 0.051907678842544554)\n",
      "('Average loss at step', 2920, 'for last 250 steps:', 0.06293267462402583)\n",
      "('Average loss at step', 2960, 'for last 250 steps:', 0.053399809487164024)\n",
      "('Average loss at step', 3000, 'for last 250 steps:', 0.05425225716084242)\n",
      "('Average loss at step', 3040, 'for last 250 steps:', 0.058832104131579396)\n",
      "('Average loss at step', 3080, 'for last 250 steps:', 0.055759835503995415)\n",
      "('Average loss at step', 3120, 'for last 250 steps:', 0.05858258839696646)\n",
      "('Average loss at step', 3160, 'for last 250 steps:', 0.059672086909413335)\n",
      "('Average loss at step', 3200, 'for last 250 steps:', 0.049196088016033174)\n",
      "('Average loss at step', 3240, 'for last 250 steps:', 0.05333805534988642)\n",
      "('Average loss at step', 3280, 'for last 250 steps:', 0.05342080408707261)\n",
      "('Average loss at step', 3320, 'for last 250 steps:', 0.05566484298557043)\n",
      "('Average loss at step', 3360, 'for last 250 steps:', 0.05605275202542544)\n",
      "('Average loss at step', 3400, 'for last 250 steps:', 0.06045425269752741)\n",
      "('Average loss at step', 3440, 'for last 250 steps:', 0.06076196484267712)\n",
      "('Average loss at step', 3480, 'for last 250 steps:', 0.0601798789575696)\n",
      "('Average loss at step', 3520, 'for last 250 steps:', 0.056746761351823806)\n",
      "('Average loss at step', 3560, 'for last 250 steps:', 0.05320189552381635)\n",
      "('Average loss at step', 3600, 'for last 250 steps:', 0.06084461111575365)\n",
      "('Average loss at step', 3640, 'for last 250 steps:', 0.057101378217339516)\n",
      "('Average loss at step', 3680, 'for last 250 steps:', 0.054961371310055254)\n",
      "('Average loss at step', 3720, 'for last 250 steps:', 0.05365585871040821)\n",
      "('Average loss at step', 3760, 'for last 250 steps:', 0.05654900886118412)\n",
      "('Average loss at step', 3800, 'for last 250 steps:', 0.05732579134404659)\n",
      "('Average loss at step', 3840, 'for last 250 steps:', 0.05041734505444765)\n",
      "('Average loss at step', 3880, 'for last 250 steps:', 0.05890305273234844)\n",
      "('Average loss at step', 3920, 'for last 250 steps:', 0.061498690769076346)\n",
      "('Average loss at step', 3960, 'for last 250 steps:', 0.05337715391069651)\n",
      "('\\nEPOCH', 6)\n",
      "('Average loss at step', 40, 'for last 250 steps:', 0.06223386943340301)\n",
      "('Average loss at step', 80, 'for last 250 steps:', 0.05541235409677028)\n",
      "('Average loss at step', 120, 'for last 250 steps:', 0.06047212667763233)\n",
      "('Average loss at step', 160, 'for last 250 steps:', 0.05352577541023493)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.06394441030919552)\n",
      "('Average loss at step', 240, 'for last 250 steps:', 0.054730330016464)\n",
      "('Average loss at step', 280, 'for last 250 steps:', 0.0603838112577796)\n",
      "('Average loss at step', 320, 'for last 250 steps:', 0.054318685457110404)\n",
      "('Average loss at step', 360, 'for last 250 steps:', 0.04960466552525759)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.045915228575468064)\n",
      "('Average loss at step', 440, 'for last 250 steps:', 0.05420735754072666)\n",
      "('Average loss at step', 480, 'for last 250 steps:', 0.057517463155090806)\n",
      "('Average loss at step', 520, 'for last 250 steps:', 0.057859880588948726)\n",
      "('Average loss at step', 560, 'for last 250 steps:', 0.04873536638915539)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.05416333541274071)\n",
      "('Average loss at step', 640, 'for last 250 steps:', 0.05751837231218815)\n",
      "('Average loss at step', 680, 'for last 250 steps:', 0.055954556036740544)\n",
      "('Average loss at step', 720, 'for last 250 steps:', 0.05566692590713501)\n",
      "('Average loss at step', 760, 'for last 250 steps:', 0.052443969659507275)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.051802553981542585)\n",
      "('Average loss at step', 840, 'for last 250 steps:', 0.057490345016121866)\n",
      "('Average loss at step', 880, 'for last 250 steps:', 0.05296709634363651)\n",
      "('Average loss at step', 920, 'for last 250 steps:', 0.055264015905559065)\n",
      "('Average loss at step', 960, 'for last 250 steps:', 0.060267871506512166)\n",
      "('Average loss at step', 1000, 'for last 250 steps:', 0.055721928216516975)\n",
      "('Average loss at step', 1040, 'for last 250 steps:', 0.05548513002693653)\n",
      "('Average loss at step', 1080, 'for last 250 steps:', 0.0484872691705823)\n",
      "('Average loss at step', 1120, 'for last 250 steps:', 0.057696074992418286)\n",
      "('Average loss at step', 1160, 'for last 250 steps:', 0.05284623336046934)\n",
      "('Average loss at step', 1200, 'for last 250 steps:', 0.05767090532928705)\n",
      "('Average loss at step', 1240, 'for last 250 steps:', 0.053793453928083185)\n",
      "('Average loss at step', 1280, 'for last 250 steps:', 0.05603574626147747)\n",
      "('Average loss at step', 1320, 'for last 250 steps:', 0.05343647617846727)\n",
      "('Average loss at step', 1360, 'for last 250 steps:', 0.05827005736529827)\n",
      "('Average loss at step', 1400, 'for last 250 steps:', 0.05984272353351116)\n",
      "('Average loss at step', 1440, 'for last 250 steps:', 0.05469773903489113)\n",
      "('Average loss at step', 1480, 'for last 250 steps:', 0.04684516403824091)\n",
      "('Average loss at step', 1520, 'for last 250 steps:', 0.05792576294392347)\n",
      "('Average loss at step', 1560, 'for last 250 steps:', 0.052332787029445174)\n",
      "('Average loss at step', 1600, 'for last 250 steps:', 0.05283100076019764)\n",
      "('Average loss at step', 1640, 'for last 250 steps:', 0.05560907663777471)\n",
      "('Average loss at step', 1680, 'for last 250 steps:', 0.06360884919762612)\n",
      "('Average loss at step', 1720, 'for last 250 steps:', 0.05875817805528641)\n",
      "('Average loss at step', 1760, 'for last 250 steps:', 0.05904657334089279)\n",
      "('Average loss at step', 1800, 'for last 250 steps:', 0.053168537225574256)\n",
      "('Average loss at step', 1840, 'for last 250 steps:', 0.05334702525287867)\n",
      "('Average loss at step', 1880, 'for last 250 steps:', 0.048505670726299285)\n",
      "('Average loss at step', 1920, 'for last 250 steps:', 0.057230562716722486)\n",
      "('Average loss at step', 1960, 'for last 250 steps:', 0.05714603491127491)\n",
      "('Average loss at step', 2000, 'for last 250 steps:', 0.0543320769071579)\n",
      "('Average loss at step', 2040, 'for last 250 steps:', 0.06279135383665561)\n",
      "('Average loss at step', 2080, 'for last 250 steps:', 0.056973689757287505)\n",
      "('Average loss at step', 2120, 'for last 250 steps:', 0.053666716553270814)\n",
      "('Average loss at step', 2160, 'for last 250 steps:', 0.05782412149012089)\n",
      "('Average loss at step', 2200, 'for last 250 steps:', 0.051888134181499485)\n",
      "('Average loss at step', 2240, 'for last 250 steps:', 0.053965949192643164)\n",
      "('Average loss at step', 2280, 'for last 250 steps:', 0.054150945730507376)\n",
      "('Average loss at step', 2320, 'for last 250 steps:', 0.05858405839651823)\n",
      "('Average loss at step', 2360, 'for last 250 steps:', 0.057113539204001425)\n",
      "('Average loss at step', 2400, 'for last 250 steps:', 0.051719712018966676)\n",
      "('Average loss at step', 2440, 'for last 250 steps:', 0.05834465749561787)\n",
      "('Average loss at step', 2480, 'for last 250 steps:', 0.05169537721201777)\n",
      "('Average loss at step', 2520, 'for last 250 steps:', 0.04661256417632103)\n",
      "('Average loss at step', 2560, 'for last 250 steps:', 0.050514564104378226)\n",
      "('Average loss at step', 2600, 'for last 250 steps:', 0.04755823437124491)\n",
      "('Average loss at step', 2640, 'for last 250 steps:', 0.05289287915453315)\n",
      "('Average loss at step', 2680, 'for last 250 steps:', 0.05032170828431845)\n",
      "('Average loss at step', 2720, 'for last 250 steps:', 0.05544615738093853)\n",
      "('Average loss at step', 2760, 'for last 250 steps:', 0.05620661778375506)\n",
      "('Average loss at step', 2800, 'for last 250 steps:', 0.05242461856454611)\n",
      "('Average loss at step', 2840, 'for last 250 steps:', 0.05611336007714272)\n",
      "('Average loss at step', 2880, 'for last 250 steps:', 0.05889015141874552)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 2920, 'for last 250 steps:', 0.06286906540393829)\n",
      "('Average loss at step', 2960, 'for last 250 steps:', 0.05737228266894817)\n",
      "('Average loss at step', 3000, 'for last 250 steps:', 0.05563269153237343)\n",
      "('Average loss at step', 3040, 'for last 250 steps:', 0.04922216944396496)\n",
      "('Average loss at step', 3080, 'for last 250 steps:', 0.06017128325998783)\n",
      "('Average loss at step', 3120, 'for last 250 steps:', 0.05224546771496534)\n",
      "('Average loss at step', 3160, 'for last 250 steps:', 0.05324473053216934)\n",
      "('Average loss at step', 3200, 'for last 250 steps:', 0.060412814505398274)\n",
      "('Average loss at step', 3240, 'for last 250 steps:', 0.05171222269535065)\n",
      "('Average loss at step', 3280, 'for last 250 steps:', 0.05901225283741951)\n",
      "('Average loss at step', 3320, 'for last 250 steps:', 0.054782560765743255)\n",
      "('Average loss at step', 3360, 'for last 250 steps:', 0.0551578626409173)\n",
      "('Average loss at step', 3400, 'for last 250 steps:', 0.05517797470092774)\n",
      "('Average loss at step', 3440, 'for last 250 steps:', 0.04946226134896278)\n",
      "('Average loss at step', 3480, 'for last 250 steps:', 0.05089498760178685)\n",
      "('Average loss at step', 3520, 'for last 250 steps:', 0.059485214203596114)\n",
      "('Average loss at step', 3560, 'for last 250 steps:', 0.05090897917747497)\n",
      "('Average loss at step', 3600, 'for last 250 steps:', 0.05114256475120783)\n",
      "('Average loss at step', 3640, 'for last 250 steps:', 0.04910695739090443)\n",
      "('Average loss at step', 3680, 'for last 250 steps:', 0.06135817328467965)\n",
      "('Average loss at step', 3720, 'for last 250 steps:', 0.057178902328014376)\n",
      "('Average loss at step', 3760, 'for last 250 steps:', 0.05453005522489548)\n",
      "('Average loss at step', 3800, 'for last 250 steps:', 0.05754647374153137)\n",
      "('Average loss at step', 3840, 'for last 250 steps:', 0.05413777630776167)\n",
      "('Average loss at step', 3880, 'for last 250 steps:', 0.05248710483312607)\n",
      "('Average loss at step', 3920, 'for last 250 steps:', 0.05560854987241328)\n",
      "('Average loss at step', 3960, 'for last 250 steps:', 0.056699462328106166)\n",
      "('\\nEPOCH', 7)\n",
      "('Average loss at step', 40, 'for last 250 steps:', 0.06125387124717235)\n",
      "('Average loss at step', 80, 'for last 250 steps:', 0.054952450208365915)\n",
      "('Average loss at step', 120, 'for last 250 steps:', 0.055351979285478595)\n",
      "('Average loss at step', 160, 'for last 250 steps:', 0.049637989662587645)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.059414854999631644)\n",
      "('Average loss at step', 240, 'for last 250 steps:', 0.0565043269097805)\n",
      "('Average loss at step', 280, 'for last 250 steps:', 0.05110272981226444)\n",
      "('Average loss at step', 320, 'for last 250 steps:', 0.05665680661797524)\n",
      "('Average loss at step', 360, 'for last 250 steps:', 0.05054780252277851)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.05772892713546753)\n",
      "('Average loss at step', 440, 'for last 250 steps:', 0.05606385231018066)\n",
      "('Average loss at step', 480, 'for last 250 steps:', 0.04936843726783991)\n",
      "('Average loss at step', 520, 'for last 250 steps:', 0.0532504017278552)\n",
      "('Average loss at step', 560, 'for last 250 steps:', 0.052858885861933234)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.04925731364637613)\n",
      "('Average loss at step', 640, 'for last 250 steps:', 0.05422296900302172)\n",
      "('Average loss at step', 680, 'for last 250 steps:', 0.055555517002940175)\n",
      "('Average loss at step', 720, 'for last 250 steps:', 0.048878272771835325)\n",
      "('Average loss at step', 760, 'for last 250 steps:', 0.05284681212157011)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.05814928568899631)\n",
      "('Average loss at step', 840, 'for last 250 steps:', 0.0513791424036026)\n",
      "('Average loss at step', 880, 'for last 250 steps:', 0.054407310783863065)\n",
      "('Average loss at step', 920, 'for last 250 steps:', 0.05473148766905069)\n",
      "('Average loss at step', 960, 'for last 250 steps:', 0.0527671068161726)\n",
      "('Average loss at step', 1000, 'for last 250 steps:', 0.046556776575744155)\n",
      "('Average loss at step', 1040, 'for last 250 steps:', 0.04760125445201993)\n",
      "('Average loss at step', 1080, 'for last 250 steps:', 0.05773748096078634)\n",
      "('Average loss at step', 1120, 'for last 250 steps:', 0.05824758641421795)\n",
      "('Average loss at step', 1160, 'for last 250 steps:', 0.05522662114351988)\n",
      "('Average loss at step', 1200, 'for last 250 steps:', 0.05205793276429176)\n",
      "('Average loss at step', 1240, 'for last 250 steps:', 0.04974976875819266)\n",
      "('Average loss at step', 1280, 'for last 250 steps:', 0.04941810701042414)\n",
      "('Average loss at step', 1320, 'for last 250 steps:', 0.05316038861870766)\n",
      "('Average loss at step', 1360, 'for last 250 steps:', 0.053780023735016586)\n",
      "('Average loss at step', 1400, 'for last 250 steps:', 0.05708108715713024)\n",
      "('Average loss at step', 1440, 'for last 250 steps:', 0.049084182269871234)\n",
      "('Average loss at step', 1480, 'for last 250 steps:', 0.05689471662044525)\n",
      "('Average loss at step', 1520, 'for last 250 steps:', 0.045387267358601095)\n",
      "('Average loss at step', 1560, 'for last 250 steps:', 0.053976474963128566)\n",
      "('Average loss at step', 1600, 'for last 250 steps:', 0.05733875170350075)\n",
      "('Average loss at step', 1640, 'for last 250 steps:', 0.056728008799254895)\n",
      "('Average loss at step', 1680, 'for last 250 steps:', 0.051277219876647)\n",
      "('Average loss at step', 1720, 'for last 250 steps:', 0.04739627558737993)\n",
      "('Average loss at step', 1760, 'for last 250 steps:', 0.0501194978132844)\n",
      "('Average loss at step', 1800, 'for last 250 steps:', 0.0506921374052763)\n",
      "('Average loss at step', 1840, 'for last 250 steps:', 0.04740865403786301)\n",
      "('Average loss at step', 1880, 'for last 250 steps:', 0.05549913428723812)\n",
      "('Average loss at step', 1920, 'for last 250 steps:', 0.05546592675149441)\n",
      "('Average loss at step', 1960, 'for last 250 steps:', 0.054243715405464174)\n",
      "('Average loss at step', 2000, 'for last 250 steps:', 0.05699116574600339)\n",
      "('Average loss at step', 2040, 'for last 250 steps:', 0.053721848502755166)\n",
      "('Average loss at step', 2080, 'for last 250 steps:', 0.06030834291130304)\n",
      "('Average loss at step', 2120, 'for last 250 steps:', 0.05219961315393448)\n",
      "('Average loss at step', 2160, 'for last 250 steps:', 0.05148131012916565)\n",
      "('Average loss at step', 2200, 'for last 250 steps:', 0.05173430971801281)\n",
      "('Average loss at step', 2240, 'for last 250 steps:', 0.05293200347572565)\n",
      "('Average loss at step', 2280, 'for last 250 steps:', 0.052477768696844576)\n",
      "('Average loss at step', 2320, 'for last 250 steps:', 0.050640830509364604)\n",
      "('Average loss at step', 2360, 'for last 250 steps:', 0.0495321699231863)\n",
      "('Average loss at step', 2400, 'for last 250 steps:', 0.05670868903398514)\n",
      "('Average loss at step', 2440, 'for last 250 steps:', 0.053187538459897044)\n",
      "('Average loss at step', 2480, 'for last 250 steps:', 0.04757538545876741)\n",
      "('Average loss at step', 2520, 'for last 250 steps:', 0.05727463498711586)\n",
      "('Average loss at step', 2560, 'for last 250 steps:', 0.04756089873611927)\n",
      "('Average loss at step', 2600, 'for last 250 steps:', 0.05358773242682219)\n",
      "('Average loss at step', 2640, 'for last 250 steps:', 0.054252482056617736)\n",
      "('Average loss at step', 2680, 'for last 250 steps:', 0.05407013520598412)\n",
      "('Average loss at step', 2720, 'for last 250 steps:', 0.04967681013047695)\n",
      "('Average loss at step', 2760, 'for last 250 steps:', 0.058433307781815526)\n",
      "('Average loss at step', 2800, 'for last 250 steps:', 0.052860602140426635)\n",
      "('Average loss at step', 2840, 'for last 250 steps:', 0.05825731121003628)\n",
      "('Average loss at step', 2880, 'for last 250 steps:', 0.05461958613246679)\n",
      "('Average loss at step', 2920, 'for last 250 steps:', 0.05752170197665692)\n",
      "('Average loss at step', 2960, 'for last 250 steps:', 0.05555196885019541)\n",
      "('Average loss at step', 3000, 'for last 250 steps:', 0.046523773297667506)\n",
      "('Average loss at step', 3040, 'for last 250 steps:', 0.05130960457026958)\n",
      "('Average loss at step', 3080, 'for last 250 steps:', 0.052004340030252935)\n",
      "('Average loss at step', 3120, 'for last 250 steps:', 0.057022134102880956)\n",
      "('Average loss at step', 3160, 'for last 250 steps:', 0.05166130937635899)\n",
      "('Average loss at step', 3200, 'for last 250 steps:', 0.05436401646584273)\n",
      "('Average loss at step', 3240, 'for last 250 steps:', 0.05055981911718845)\n",
      "('Average loss at step', 3280, 'for last 250 steps:', 0.05328594893217087)\n",
      "('Average loss at step', 3320, 'for last 250 steps:', 0.05384419731795788)\n",
      "('Average loss at step', 3360, 'for last 250 steps:', 0.05591365538537502)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 3400, 'for last 250 steps:', 0.05275844104588032)\n",
      "('Average loss at step', 3440, 'for last 250 steps:', 0.05364502757787704)\n",
      "('Average loss at step', 3480, 'for last 250 steps:', 0.054411569330841306)\n",
      "('Average loss at step', 3520, 'for last 250 steps:', 0.05529086343944073)\n",
      "('Average loss at step', 3560, 'for last 250 steps:', 0.054541450515389445)\n",
      "('Average loss at step', 3600, 'for last 250 steps:', 0.0472276826761663)\n",
      "('Average loss at step', 3640, 'for last 250 steps:', 0.054417113028466704)\n",
      "('Average loss at step', 3680, 'for last 250 steps:', 0.05474153447896242)\n",
      "('Average loss at step', 3720, 'for last 250 steps:', 0.05249707572162152)\n",
      "('Average loss at step', 3760, 'for last 250 steps:', 0.04553873714059591)\n",
      "('Average loss at step', 3800, 'for last 250 steps:', 0.05453128382563591)\n",
      "('Average loss at step', 3840, 'for last 250 steps:', 0.05151906261220574)\n",
      "('Average loss at step', 3880, 'for last 250 steps:', 0.053006858378648755)\n",
      "('Average loss at step', 3920, 'for last 250 steps:', 0.05306457530707121)\n",
      "('Average loss at step', 3960, 'for last 250 steps:', 0.05121131332591176)\n",
      "('\\nEPOCH', 8)\n",
      "('Average loss at step', 40, 'for last 250 steps:', 0.05450063314288855)\n",
      "('Average loss at step', 80, 'for last 250 steps:', 0.05402501579374075)\n",
      "('Average loss at step', 120, 'for last 250 steps:', 0.05359843201935291)\n",
      "('Average loss at step', 160, 'for last 250 steps:', 0.05511194836348295)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.05027253687381744)\n",
      "('Average loss at step', 240, 'for last 250 steps:', 0.058685426451265815)\n",
      "('Average loss at step', 280, 'for last 250 steps:', 0.056252899318933486)\n",
      "('Average loss at step', 320, 'for last 250 steps:', 0.057725541926920414)\n",
      "('Average loss at step', 360, 'for last 250 steps:', 0.052024919651448724)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.0574884456768632)\n",
      "('Average loss at step', 440, 'for last 250 steps:', 0.04391609791666269)\n",
      "('Average loss at step', 480, 'for last 250 steps:', 0.05910670101642609)\n",
      "('Average loss at step', 520, 'for last 250 steps:', 0.04922842264175415)\n",
      "('Average loss at step', 560, 'for last 250 steps:', 0.052434198558330536)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.04857366591691971)\n",
      "('Average loss at step', 640, 'for last 250 steps:', 0.05801045574247837)\n",
      "('Average loss at step', 680, 'for last 250 steps:', 0.0518946254439652)\n",
      "('Average loss at step', 720, 'for last 250 steps:', 0.05193000037223101)\n",
      "('Average loss at step', 760, 'for last 250 steps:', 0.051230992432683704)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.05094688672572374)\n",
      "('Average loss at step', 840, 'for last 250 steps:', 0.05617070071399212)\n",
      "('Average loss at step', 880, 'for last 250 steps:', 0.04727176003158093)\n",
      "('Average loss at step', 920, 'for last 250 steps:', 0.052386192604899406)\n",
      "('Average loss at step', 960, 'for last 250 steps:', 0.05392647810280323)\n",
      "('Average loss at step', 1000, 'for last 250 steps:', 0.049984330236911775)\n",
      "('Average loss at step', 1040, 'for last 250 steps:', 0.04977553427219391)\n",
      "('Average loss at step', 1080, 'for last 250 steps:', 0.05618540745228529)\n",
      "('Average loss at step', 1120, 'for last 250 steps:', 0.05317401386797428)\n",
      "('Average loss at step', 1160, 'for last 250 steps:', 0.0478793085180223)\n",
      "('Average loss at step', 1200, 'for last 250 steps:', 0.049325210601091386)\n",
      "('Average loss at step', 1240, 'for last 250 steps:', 0.0588328655064106)\n",
      "('Average loss at step', 1280, 'for last 250 steps:', 0.04887696452438831)\n",
      "('Average loss at step', 1320, 'for last 250 steps:', 0.04953836772590876)\n",
      "('Average loss at step', 1360, 'for last 250 steps:', 0.0519277011230588)\n",
      "('Average loss at step', 1400, 'for last 250 steps:', 0.05425774671137333)\n",
      "('Average loss at step', 1440, 'for last 250 steps:', 0.0437472040951252)\n",
      "('Average loss at step', 1480, 'for last 250 steps:', 0.051065437812358144)\n",
      "('Average loss at step', 1520, 'for last 250 steps:', 0.05416316224262118)\n",
      "('Average loss at step', 1560, 'for last 250 steps:', 0.046694610603153705)\n",
      "('Average loss at step', 1600, 'for last 250 steps:', 0.0474499449878931)\n",
      "('Average loss at step', 1640, 'for last 250 steps:', 0.05375637501478195)\n",
      "('Average loss at step', 1680, 'for last 250 steps:', 0.05332717683166265)\n",
      "('Average loss at step', 1720, 'for last 250 steps:', 0.049586315602064134)\n",
      "('Average loss at step', 1760, 'for last 250 steps:', 0.04609121076762676)\n",
      "('Average loss at step', 1800, 'for last 250 steps:', 0.054425513297319414)\n",
      "('Average loss at step', 1840, 'for last 250 steps:', 0.05164766192436218)\n",
      "('Average loss at step', 1880, 'for last 250 steps:', 0.05411258675158024)\n",
      "('Average loss at step', 1920, 'for last 250 steps:', 0.05759281367063522)\n",
      "('Average loss at step', 1960, 'for last 250 steps:', 0.050239923372864724)\n",
      "('Average loss at step', 2000, 'for last 250 steps:', 0.05723439991474152)\n",
      "('Average loss at step', 2040, 'for last 250 steps:', 0.05035858841612935)\n",
      "('Average loss at step', 2080, 'for last 250 steps:', 0.05499989189207554)\n",
      "('Average loss at step', 2120, 'for last 250 steps:', 0.05424408413469792)\n",
      "('Average loss at step', 2160, 'for last 250 steps:', 0.053384521454572675)\n",
      "('Average loss at step', 2200, 'for last 250 steps:', 0.051471114866435526)\n",
      "('Average loss at step', 2240, 'for last 250 steps:', 0.05449331026524305)\n",
      "('Average loss at step', 2280, 'for last 250 steps:', 0.046865896098315714)\n",
      "('Average loss at step', 2320, 'for last 250 steps:', 0.057773227281868456)\n",
      "('Average loss at step', 2360, 'for last 250 steps:', 0.05058084115386009)\n",
      "('Average loss at step', 2400, 'for last 250 steps:', 0.05688763685524464)\n",
      "('Average loss at step', 2440, 'for last 250 steps:', 0.055121506340801714)\n",
      "('Average loss at step', 2480, 'for last 250 steps:', 0.052080248668789866)\n",
      "('Average loss at step', 2520, 'for last 250 steps:', 0.05030732620507479)\n",
      "('Average loss at step', 2560, 'for last 250 steps:', 0.049054198078811166)\n",
      "('Average loss at step', 2600, 'for last 250 steps:', 0.056257689148187635)\n",
      "('Average loss at step', 2640, 'for last 250 steps:', 0.053402984105050566)\n",
      "('Average loss at step', 2680, 'for last 250 steps:', 0.0596033088862896)\n",
      "('Average loss at step', 2720, 'for last 250 steps:', 0.05445985740050673)\n",
      "('Average loss at step', 2760, 'for last 250 steps:', 0.04724230702966452)\n",
      "('Average loss at step', 2800, 'for last 250 steps:', 0.048665932305157186)\n",
      "('Average loss at step', 2840, 'for last 250 steps:', 0.05225481666624546)\n",
      "('Average loss at step', 2880, 'for last 250 steps:', 0.05421579513698816)\n",
      "('Average loss at step', 2920, 'for last 250 steps:', 0.05054950714111328)\n",
      "('Average loss at step', 2960, 'for last 250 steps:', 0.053273929990828035)\n",
      "('Average loss at step', 3000, 'for last 250 steps:', 0.048073209412395956)\n",
      "('Average loss at step', 3040, 'for last 250 steps:', 0.056367564648389816)\n",
      "('Average loss at step', 3080, 'for last 250 steps:', 0.05489080399274826)\n",
      "('Average loss at step', 3120, 'for last 250 steps:', 0.052901879623532294)\n",
      "('Average loss at step', 3160, 'for last 250 steps:', 0.051629289612174036)\n",
      "('Average loss at step', 3200, 'for last 250 steps:', 0.05335633438080549)\n",
      "('Average loss at step', 3240, 'for last 250 steps:', 0.050586347244679926)\n",
      "('Average loss at step', 3280, 'for last 250 steps:', 0.049569830670952796)\n",
      "('Average loss at step', 3320, 'for last 250 steps:', 0.054294009245932105)\n",
      "('Average loss at step', 3360, 'for last 250 steps:', 0.050800297781825064)\n",
      "('Average loss at step', 3400, 'for last 250 steps:', 0.052244882956147196)\n",
      "('Average loss at step', 3440, 'for last 250 steps:', 0.04608650293201208)\n",
      "('Average loss at step', 3480, 'for last 250 steps:', 0.05341084107756615)\n",
      "('Average loss at step', 3520, 'for last 250 steps:', 0.05452744975686073)\n",
      "('Average loss at step', 3560, 'for last 250 steps:', 0.051098907738924025)\n",
      "('Average loss at step', 3600, 'for last 250 steps:', 0.048483488708734514)\n",
      "('Average loss at step', 3640, 'for last 250 steps:', 0.051183752082288266)\n",
      "('Average loss at step', 3680, 'for last 250 steps:', 0.050045973025262355)\n",
      "('Average loss at step', 3720, 'for last 250 steps:', 0.04874013975262642)\n",
      "('Average loss at step', 3760, 'for last 250 steps:', 0.045275801047682765)\n",
      "('Average loss at step', 3800, 'for last 250 steps:', 0.051019872799515725)\n",
      "('Average loss at step', 3840, 'for last 250 steps:', 0.04868356436491013)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 3880, 'for last 250 steps:', 0.04902859631925821)\n",
      "('Average loss at step', 3920, 'for last 250 steps:', 0.04798102505505085)\n",
      "('Average loss at step', 3960, 'for last 250 steps:', 0.050633953660726545)\n",
      "('\\nEPOCH', 9)\n",
      "('Average loss at step', 40, 'for last 250 steps:', 0.0535687118396163)\n",
      "('Average loss at step', 80, 'for last 250 steps:', 0.055827782824635505)\n",
      "('Average loss at step', 120, 'for last 250 steps:', 0.0486322333291173)\n",
      "('Average loss at step', 160, 'for last 250 steps:', 0.04926859512925148)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.050444849915802475)\n",
      "('Average loss at step', 240, 'for last 250 steps:', 0.05002686398103833)\n",
      "('Average loss at step', 280, 'for last 250 steps:', 0.04979248646646738)\n",
      "('Average loss at step', 320, 'for last 250 steps:', 0.05311309300363064)\n",
      "('Average loss at step', 360, 'for last 250 steps:', 0.05069215739145875)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.04787358390167355)\n",
      "('Average loss at step', 440, 'for last 250 steps:', 0.05538528922945261)\n",
      "('Average loss at step', 480, 'for last 250 steps:', 0.05124098815023899)\n",
      "('Average loss at step', 520, 'for last 250 steps:', 0.05187032144516707)\n",
      "('Average loss at step', 560, 'for last 250 steps:', 0.050039728060364726)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.05200488790869713)\n",
      "('Average loss at step', 640, 'for last 250 steps:', 0.04938909642398357)\n",
      "('Average loss at step', 680, 'for last 250 steps:', 0.05500085838139057)\n",
      "('Average loss at step', 720, 'for last 250 steps:', 0.05600124962627888)\n",
      "('Average loss at step', 760, 'for last 250 steps:', 0.05170695804059505)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.04742972780019045)\n",
      "('Average loss at step', 840, 'for last 250 steps:', 0.05060123167932033)\n",
      "('Average loss at step', 880, 'for last 250 steps:', 0.054799087680876254)\n",
      "('Average loss at step', 920, 'for last 250 steps:', 0.04796396646648646)\n",
      "('Average loss at step', 960, 'for last 250 steps:', 0.04893664168193936)\n",
      "('Average loss at step', 1000, 'for last 250 steps:', 0.05174480311572552)\n",
      "('Average loss at step', 1040, 'for last 250 steps:', 0.051911294907331464)\n",
      "('Average loss at step', 1080, 'for last 250 steps:', 0.04612020257860422)\n",
      "('Average loss at step', 1120, 'for last 250 steps:', 0.05158695716410875)\n",
      "('Average loss at step', 1160, 'for last 250 steps:', 0.05269153571687639)\n",
      "('Average loss at step', 1200, 'for last 250 steps:', 0.05160849709063768)\n",
      "('Average loss at step', 1240, 'for last 250 steps:', 0.04634546089917421)\n",
      "('Average loss at step', 1280, 'for last 250 steps:', 0.04621803317219019)\n",
      "('Average loss at step', 1320, 'for last 250 steps:', 0.05226118467748165)\n",
      "('Average loss at step', 1360, 'for last 250 steps:', 0.05648315265774727)\n",
      "('Average loss at step', 1400, 'for last 250 steps:', 0.0472935738414526)\n",
      "('Average loss at step', 1440, 'for last 250 steps:', 0.04831698417663574)\n",
      "('Average loss at step', 1480, 'for last 250 steps:', 0.04945411082357168)\n",
      "('Average loss at step', 1520, 'for last 250 steps:', 0.048814699314534665)\n",
      "('Average loss at step', 1560, 'for last 250 steps:', 0.046442025899887086)\n",
      "('Average loss at step', 1600, 'for last 250 steps:', 0.05145573768764734)\n",
      "('Average loss at step', 1640, 'for last 250 steps:', 0.051002044063061476)\n",
      "('Average loss at step', 1680, 'for last 250 steps:', 0.04410683836787939)\n",
      "('Average loss at step', 1720, 'for last 250 steps:', 0.04849243365228176)\n",
      "('Average loss at step', 1760, 'for last 250 steps:', 0.051761905513703826)\n",
      "('Average loss at step', 1800, 'for last 250 steps:', 0.048643599711358544)\n",
      "('Average loss at step', 1840, 'for last 250 steps:', 0.048166486993432046)\n",
      "('Average loss at step', 1880, 'for last 250 steps:', 0.05407576411962509)\n",
      "('Average loss at step', 1920, 'for last 250 steps:', 0.04725714506581426)\n",
      "('Average loss at step', 1960, 'for last 250 steps:', 0.04919520674273372)\n",
      "('Average loss at step', 2000, 'for last 250 steps:', 0.053045746386051175)\n",
      "('Average loss at step', 2040, 'for last 250 steps:', 0.04701390691101551)\n",
      "('Average loss at step', 2080, 'for last 250 steps:', 0.05034339090809226)\n",
      "('Average loss at step', 2120, 'for last 250 steps:', 0.04800303112715483)\n",
      "('Average loss at step', 2160, 'for last 250 steps:', 0.04436291914433241)\n",
      "('Average loss at step', 2200, 'for last 250 steps:', 0.04614656548947096)\n",
      "('Average loss at step', 2240, 'for last 250 steps:', 0.05715081624686718)\n",
      "('Average loss at step', 2280, 'for last 250 steps:', 0.0448275513574481)\n",
      "('Average loss at step', 2320, 'for last 250 steps:', 0.05171050930395722)\n",
      "('Average loss at step', 2360, 'for last 250 steps:', 0.047009305357933046)\n",
      "('Average loss at step', 2400, 'for last 250 steps:', 0.05137746121734381)\n",
      "('Average loss at step', 2440, 'for last 250 steps:', 0.05553616724908352)\n",
      "('Average loss at step', 2480, 'for last 250 steps:', 0.045200174190104005)\n",
      "('Average loss at step', 2520, 'for last 250 steps:', 0.04355557590723038)\n",
      "('Average loss at step', 2560, 'for last 250 steps:', 0.0441926597058773)\n",
      "('Average loss at step', 2600, 'for last 250 steps:', 0.049626905508339404)\n",
      "('Average loss at step', 2640, 'for last 250 steps:', 0.05045015174895525)\n",
      "('Average loss at step', 2680, 'for last 250 steps:', 0.039197611971758306)\n",
      "('Average loss at step', 2720, 'for last 250 steps:', 0.046349865682423115)\n",
      "('Average loss at step', 2760, 'for last 250 steps:', 0.05639366570860147)\n",
      "('Average loss at step', 2800, 'for last 250 steps:', 0.05724046166986227)\n",
      "('Average loss at step', 2840, 'for last 250 steps:', 0.050159265473484996)\n",
      "('Average loss at step', 2880, 'for last 250 steps:', 0.057731462195515636)\n",
      "('Average loss at step', 2920, 'for last 250 steps:', 0.0482241790369153)\n",
      "('Average loss at step', 2960, 'for last 250 steps:', 0.047719821184873584)\n",
      "('Average loss at step', 3000, 'for last 250 steps:', 0.05162073075771332)\n",
      "('Average loss at step', 3040, 'for last 250 steps:', 0.048674113564193246)\n",
      "('Average loss at step', 3080, 'for last 250 steps:', 0.05242968255653977)\n",
      "('Average loss at step', 3120, 'for last 250 steps:', 0.047276456244289874)\n",
      "('Average loss at step', 3160, 'for last 250 steps:', 0.052875658236443995)\n",
      "('Average loss at step', 3200, 'for last 250 steps:', 0.04976666413247585)\n",
      "('Average loss at step', 3240, 'for last 250 steps:', 0.05273812662810087)\n",
      "('Average loss at step', 3280, 'for last 250 steps:', 0.049619589261710645)\n",
      "('Average loss at step', 3320, 'for last 250 steps:', 0.05034874456003308)\n",
      "('Average loss at step', 3360, 'for last 250 steps:', 0.050528933592140675)\n",
      "('Average loss at step', 3400, 'for last 250 steps:', 0.0442489555105567)\n",
      "('Average loss at step', 3440, 'for last 250 steps:', 0.04814433217048645)\n",
      "('Average loss at step', 3480, 'for last 250 steps:', 0.05252849655225873)\n",
      "('Average loss at step', 3520, 'for last 250 steps:', 0.04949953511357307)\n",
      "('Average loss at step', 3560, 'for last 250 steps:', 0.04893578045070171)\n",
      "('Average loss at step', 3600, 'for last 250 steps:', 0.044289345890283584)\n",
      "('Average loss at step', 3640, 'for last 250 steps:', 0.05601692087948322)\n",
      "('Average loss at step', 3680, 'for last 250 steps:', 0.04804985508322716)\n",
      "('Average loss at step', 3720, 'for last 250 steps:', 0.04952753838151693)\n",
      "('Average loss at step', 3760, 'for last 250 steps:', 0.05367119763046503)\n",
      "('Average loss at step', 3800, 'for last 250 steps:', 0.04981128338724375)\n",
      "('Average loss at step', 3840, 'for last 250 steps:', 0.04757289957255125)\n",
      "('Average loss at step', 3880, 'for last 250 steps:', 0.04932524163275957)\n",
      "('Average loss at step', 3920, 'for last 250 steps:', 0.05059840504080057)\n",
      "('Average loss at step', 3960, 'for last 250 steps:', 0.048752596229314805)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10f2c8c50>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(10,num_steps, state_size)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
